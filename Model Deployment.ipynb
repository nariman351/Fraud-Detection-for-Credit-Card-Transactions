{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zObDiOTvwcNK"
      },
      "outputs": [],
      "source": [
        "bucket = 'xgboostbucket'\n",
        "prefix = 'dataset'\n",
        "key = 'dataset/credit_card_transactions-ibm_v2.csv'\n",
        "# Define IAM role\n",
        "import boto3\n",
        "import re\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import sklearn\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import classification_report\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "\n",
        "\n",
        "import matplotlib.pyplot as plt\n",
        "import os\n",
        "import sagemaker\n",
        "from sagemaker import get_execution_role\n",
        "from sagemaker.inputs import TrainingInput\n",
        "from sagemaker.serializers import CSVSerializer\n",
        "import io\n",
        "s3 = boto3.client('s3')\n",
        "role = get_execution_role()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "3OYD3X3xwm7m"
      },
      "outputs": [],
      "source": [
        "obj = s3.get_object(Bucket=bucket, Key=key)\n",
        "df = pd.read_csv(obj.get(\"Body\"),nrows=1000000)\n",
        "df.head() "
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Preprocessing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nDz_1PbNwo6X"
      },
      "outputs": [],
      "source": [
        "df['Is Fraud?']=df['Is Fraud?'].replace({'No':0,'Yes':1}) \n",
        "df['Errors?']=df['Errors?'].fillna('NAN')\n",
        "df['Errors?']=df['Errors?'].apply(lambda value:value=='NAN')\n",
        "df['Use Chip'].unique()\n",
        "df['is online']=df['Use Chip'].apply(lambda value:value=='Online Transaction')\n",
        "df['Use Chip']=df['Use Chip'].replace({'Swipe Transaction':0, 'Online Transaction':1, 'Chip Transaction':2})\n",
        "df['Zip'] = df['Zip'].fillna(df['Zip'].mean())  \n",
        "df['Amount'] = df['Amount'].apply(lambda value: float(value.split(\"$\")[1]))\n",
        "df['Hour'] = df['Time'].apply(lambda value: int(value.split(\":\")[0]))\n",
        "df['Minutes'] = df['Time'].apply(lambda value: int(value.split(\":\")[1]))\n",
        "df.drop(['Time'], axis=1, inplace=True)     \n",
        "df['Merchant State']=df['Merchant State'].fillna('NAN')    \n",
        "df['Merchant City']=df['Merchant City'].fillna('NAN') \n",
        "df['is vozmes']=df['Amount'].apply(lambda value: value<0)  \n",
        "df['abs_amount']=df['Amount'].apply(lambda value: abs(value))\n",
        "le=LabelEncoder() \n",
        "df['Merchant State']=le.fit_transform(df['Merchant State'])\n",
        "le=LabelEncoder()\n",
        "df['Merchant City']=le.fit_transform(df['Merchant City'])\n",
        "df.drop('Merchant Name',axis=1,inplace=True)\n",
        "df.drop('User',axis=1,inplace=True)\n",
        "df = pd.concat([df['Is Fraud?'], df.drop(['Is Fraud?'], axis=1)], axis=1)\n",
        "df.replace({False: 0, True: 1}, inplace=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "c7Gpe2pUwqDr"
      },
      "outputs": [],
      "source": [
        "df.head(1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AsPDtNVbwq6q"
      },
      "outputs": [],
      "source": [
        "train_data, validation_data, test_data = np.split(df.sample(frac=1, random_state=42), [int(0.7 * len(df)), int(0.9 * len(df))])\n",
        "train_data.to_csv('train.csv', header=False, index=False)\n",
        "validation_data.to_csv('validation.csv', header=False, index=False)\n",
        "test_data.to_csv('test.csv', header=False, index=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2vv3vh_hwroW"
      },
      "outputs": [],
      "source": [
        "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'train/train.csv')).upload_file('train.csv')\n",
        "boto3.Session().resource('s3').Bucket(bucket).Object(os.path.join(prefix, 'validation/validation.csv')).upload_file('validation.csv')\n",
        "s3_input_train = TrainingInput(s3_data='s3://{}/{}/train'.format(bucket, prefix), content_type='csv')\n",
        "s3_input_validation = TrainingInput(s3_data='s3://{}/{}/validation/'.format(bucket, prefix), content_type='csv')"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Training:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bs45k8EnwsYP"
      },
      "outputs": [],
      "source": [
        "containers = {'us-west-2': '433757028032.dkr.ecr.us-west-2.amazonaws.com/xgboost:latest',\n",
        "              'us-east-1': '811284229777.dkr.ecr.us-east-1.amazonaws.com/xgboost:latest',\n",
        "              'us-east-2': '825641698319.dkr.ecr.us-east-2.amazonaws.com/xgboost:latest',\n",
        "              'eu-west-1': '685385470294.dkr.ecr.eu-west-1.amazonaws.com/xgboost:latest'}\n",
        "\n",
        "sess = sagemaker.Session()\n",
        "xgb = sagemaker.estimator.Estimator(containers[boto3.Session().region_name],\n",
        "                                    role, \n",
        "                                    instance_count=1, \n",
        "                                    instance_type='ml.m4.xlarge',\n",
        "                                    output_path='s3://{}/{}/output'.format(bucket, prefix),\n",
        "                                    sagemaker_session=sess)\n",
        "xgb.set_hyperparameters(eta=0.1, objective='binary:logistic', num_round=25) \n",
        "xgb.fit({'train': s3_input_train, 'validation': s3_input_validation})"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Deployment:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "-qS3lD2ZwtjA"
      },
      "outputs": [],
      "source": [
        "xgb_predictor = xgb.deploy(\n",
        "\tinitial_instance_count = 1,\n",
        "\tinstance_type = 'ml.m4.xlarge',\n",
        "\tserializer = CSVSerializer())"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Testing:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "CGxP0CB6wuaD"
      },
      "outputs": [],
      "source": [
        "def predict(data, rows=500):\n",
        "    split_array = np.array_split(data, int(data.shape[0] / float(rows) + 1))\n",
        "    predictions = ''\n",
        "    for array in split_array:\n",
        "        predictions = ','.join([predictions, xgb_predictor.predict(array).decode('utf-8')])\n",
        "        p = np.fromstring(predictions[1:], sep=',')\n",
        "        p = np.round(p)\n",
        "\n",
        "    return p\n",
        "\n",
        "predictions = predict(test_data.to_numpy()[:,1:])\n",
        "predictions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Lz-iEweywv4_"
      },
      "outputs": [],
      "source": [
        "import boto3\n",
        "import numpy as np\n",
        "# copy endpoint name u got from endpoint name print() or uploaded one and copy it here\n",
        "ENDPOINT_NAME = 'xgboost-2022-05-10-20-38-39-998'\n",
        "runtime = boto3.client('runtime.sagemaker')\n",
        "\n",
        "def lambda_handler(event, context):\n",
        "  inputs = event['data']\n",
        "  result = []\n",
        "  for input in inputs:\n",
        "    serialized_input = ','.join(map(str, input))\n",
        "\n",
        "    response = runtime.invoke_endpoint(EndpointName=ENDPOINT_NAME,\n",
        "                                     ContentType='text/csv',\n",
        "                                     Body=serialized_input)\n",
        "  \n",
        "    result.append(response['Body'].read().decode())\n",
        "\n",
        "  return result\n",
        "\n",
        "input_json = { \"data\":\n",
        "        [[0,2017,10,10,4.02,2,12095,146,29693.0,5814,1,0,11,19,0,4.02],\n",
        "         [0,2017,10,10,4.02,2,12095,146,29693.0,5814,1,0,11,19,0,4.02],\n",
        "         [0,2017,10,10,4.02,2,12095,146,29693.0,5814,1,0,11,19,0,4.02],\n",
        "         [0,2017,10,10,4.02,2,12095,146,29693.0,5814,1,0,11,19,0,4.02]]\n",
        "}\n",
        "\n",
        "result = lambda_handler(input_json, _)\n",
        "result"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "collapsed_sections": [],
      "name": "xgboostAWS.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
